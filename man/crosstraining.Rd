% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machinelearning.R
\name{crosstraining}
\alias{crosstraining}
\title{Cross-training for ensemble or elastic net models}
\usage{
crosstraining(
  orivar,
  oripd,
  fold = 0.9,
  roundnum = 10,
  cores = 1,
  learner = 1,
  samplenum = 10,
  binwith = 1,
  alphas = c(0.5),
  errortype = "min",
  localrsquare = FALSE,
  plotting = FALSE,
  prescreen = FALSE
)
}
\arguments{
\item{orivar}{A matrix recording the values of candidate features for all
samples (training samples + testing samples). Each row represents one
sample and each column represents one feature. The column names are the
feature names while the row names should be sample IDs. Each column
records a series of numeric values.}

\item{oripd}{A data.frame indicating the meta information of all samples
(training samples + testing samples). Each row represents one sample and
each column represents one feature. Two columns must be included in this
data.frame, one is a column named "sampleid", which records the unique IDs
of samples, and the other is a column named "Response", which records the
values of the response variable that will be used to construct the
downstream ensemble model, and this column can be a factor, or record
numeric values. If it is a factor, it will be converted to numeric values.}

\item{fold}{A float number between 0 and 1, indicating the proportion of
total samples that will be included in the training dataset for each
sample dividing round, so that the proportion of total samples that will
be included in the testing dataset is \code{1 - fold}. Default is 0.9.}

\item{roundnum}{Number of rounds need to divide the original dataset into
training and testing to train the models. It can also be understood as the
number of ensemble or elastic net models need to be trained. Default value
is 10.}

\item{cores}{Number of threads need to be used to parallelize the computing.
Default is 1.}

\item{learner}{What kind of models need to be trained. If it is set as 1,
the models will be ensemble models with elastic net base learners, and for
each base learner, its training sample distribution will be adjusted to a
balance status via over-sampling and under-sampling. The over-sampling
will be performed using a SMOTE method, while the under-sampling will be
performed using a bootstrapping method. If it is set as 2, also ensemble
models with distribution adjustment will be trained. Its difference from 1
is that both the over-sampling and under-sampling are performed using a
bootstrapping strategy. If it is set as 3, ensemble models without sample
distribution adjustment will be trained. If this parameter is 4, simple
elastic net models will be trained. Default is 1.}

\item{samplenum}{If set \code{learner} as 1, 2, or 3, i.e., the models are
set as ensemble models, for each dividing round, after getting the
training dataset, several rounds of sampling need to be further performed
on the training dataset to train several base learners and then construct
the ensemble model. It can also be understood as the number of base
learners included in one ensemble model generated from one round of
training/testing division. Default is 10.}

\item{binwith}{If the parameter \code{learner} is set as 1 or 2, i.e. the
training sample distribution need to be adjusted before training a base
learner, this parameter will be needed to set the start value of the bin
width to divide the response variable and to measure and adjust this
distribution. Its default value is 1.}

\item{alphas}{A vector with the candidate elastic net mixing parameters,
which should be between 0 and 1. If the mixing parameter (alpha) is 1, the
regularization is actually a LASSO regularization. If alpha is 0, the
regularization is actually a ridge regularization. Default is 0.5.}

\item{errortype}{The method to automatically choose the regularization
constant lambda and the elastic net mixing parameter alpha for each
elastic net model. If it is "min", the lambda and alpha combination
giving minimum mean 10-fold cross-validation error on the specific
training set of the model will be used, while if it is "1ses", the lambda
and alpha combination giving the cross-validation error within one
standard error of the minimum will be used. Default is "min".}

\item{localrsquare}{Whether the local R squares of several small sample
groups within specific response value intervals need to be calculated.
Default is FALSE.}

\item{plotting}{Whether several plots need to be generated to show the
performance of the models. Each model for each training/testing division
round will get a set of plots, including the scatter plots, heatmap plots,
and residual plots on both training and testing datasets. Default value
is FALSE.}

\item{prescreen}{If this parameter is set as TRUE, before the model
construction, a preliminary screen on the features included in
\code{orivar} will be performed first according to the p-value of their
Pearson correlation coefficients to the response variable, and the ones
with such a p-value less than 0.05 will be selected to train the model.
Default is FALSE.}
}
\value{
A list with several slots. The slot named "modellist" is a sub-list,
which contains the model training results for all the training/testing
division rounds, and each of its elements corresponds to a single round.
The slots "traininglist" and "testinglist" record the sample IDs of the
training and testing sets for each round. The slots "trainingsummary" and
"testingsummary" record the metrics reflecting the model performance on
training and testing sets for the rounds, including the R square and the
MSE (mean squared error) of the models. If the parameter \code{plotting}
is set as TRUE, several plots reflecting the model performances will also
be returned.
}
\description{
Divide the original dataset into training and testing for several rounds and
then for each round, train an ensemble or elastic net model.
}
