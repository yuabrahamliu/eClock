% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machinelearning.R
\name{singlebalance}
\alias{singlebalance}
\title{Train an ensemble elastic net model to fit the response and do feature
selection}
\usage{
singlebalance(
  orivar,
  oripd,
  fold = 0.9,
  seednum = 1,
  cores = 1,
  balancing = TRUE,
  samplenum = 10,
  binwith = 1,
  upsampling = "SMOTE",
  alphas = c(0.5),
  errortype = "min",
  localrsquare = FALSE,
  plotting = FALSE,
  balanceidx = FALSE,
  prescreen = FALSE
)
}
\arguments{
\item{orivar}{A matrix recording the values of candidate features for all
samples (training samples + testing samples). Each row represents one
sample and each column represents one feature. The column names are the
feature names while the row names should be sample IDs. Each column
records a series of numeric values.}

\item{oripd}{A data.frame indicating the meta information of all samples
(training samples + testing samples). Each row represents one sample and
each column represents one feature. Two columns must be included in this
data.frame, one is a column named "sampleid", which records the unique IDs
of samples, and the other is a column named "Response", which records the
values of the response variable that will be used to construct the
downstream ensemble model, and this column can be a factor, or record
numeric values. If it is a factor, it will be converted to numeric values.}

\item{fold}{A float number between 0 and 1, indicating the proportion of
total samples that will be included in the training dataset, so that the
proportion of total samples that will be included in the testing dataset
is \code{1 - fold}. Default is 0.9.}

\item{seednum}{Random seed need to be set for dividing the dataset into
training and testing randomly. Default is 1.}

\item{cores}{Number of threads need to be used to parallelize the computing.
Default is 1.}

\item{balancing}{When taking samples to construct base learners, whether a
balancing sampling strategy, or a normal bootstrapping sampling strategy
should be used. If it is TRUE, a balancing sampling strategy will be used,
which means the original response distribution of the training samples
will be adjusted to a balanced one via over-sampling on the samples with
low distribution density and under-sampling on the ones with high
distribution density. If it is FALSE, a normal bootstrapping sampling will
be used and the original sample distribution will not be adjusted. Default
is TRUE.}

\item{samplenum}{The number of sampling rounds need to be taken to construct
the ensemble model. It can also be understood as the number of base
learners included in the model. Default is 10.}

\item{binwith}{If the parameter \code{balancing} or \code{balanceidx} is set
as TRUE, this parameter will be needed to set the start value of the bin
width to divide the response variable and to measure this distribution.
Its default value is 1.}

\item{upsampling}{If the parameter \code{balancing} is set as TRUE, this
parameter will be needed to set the method to do over-sampling for the
samples with a low response distribution density. The over-sampling will
make the density of these samples increase to the level of other samples.
Its default value is "SMOTE", which means that the SMOTE (Synthetic
Minority Over-sampling Technique) method will be used. The value of this
parameter can also be "boot", which means bootstrapping will be used, but
it is not recommended because it is more likely to bring over-fitting
problems.}

\item{alphas}{A vector with the candidate elastic net mixing parameters,
which should be between 0 and 1. If the mixing parameter (alpha) is 1, the
regularization is actually a LASSO regularization. If alpha is 0, the
regularization is actually a ridge regularization. Default is 0.5.}

\item{errortype}{The method to automatically choose the regularization
constant lambda and the elastic net mixing parameter alpha for each
elastic net base learner. If it is "min", the lambda and alpha combination
giving minimum mean 10-fold cross-validation error on the sampled training
set of the base learner will be used, while if it is "1ses", the lambda
and alpha combination giving the cross-validation error within one
standard error of the minimum will be used. Default is "min".}

\item{localrsquare}{Whether the local R squares of several small sample
groups within specific response value intervals need to be calculated.
Default is FALSE.}

\item{plotting}{Whether several plots need to be generated to show the
performance of the model, including the scatter plots, heatmap plots, and
residual plots on both training and testing datasets. Default is FALSE.}

\item{balanceidx}{Whether or not to calculate the balance index of the
original training data response distribution.}

\item{prescreen}{If this parameter is set as TRUE, before the model
construction, a preliminary screen on the features included in
\code{orivar} will be performed first according to the p-value of their
Pearson correlation coefficients to the response variable, and the ones
with such a p-value less than 0.05 will be selected to train the model.
Default is FALSE.}
}
\value{
A list with several slots. The slot named "baselearners" contains S3
objects for the base learners. The slot "baseweights" records the weights
of the base learners when using them to construct the ensemble model. The
slots "traincomp" and "testcomp" are data.frames with the predicted and
true response values for training and testing datasets. The column names
are "Prediction" and "True", the row names are the sample IDs. The slot
"modelscores" records the features finally selected and their scores
reflecting their importance. The slot "modelcoefs" records the regression
coefficients for all the selected features as well as the intercepts in
the base learners. The slot "balanceidx" is the balance index of the
response distribution of the original training dataset. If the parameter
\code{plotting} is set as TRUE, several plots reflecting the ensemble
model performance will also be returned.
}
\description{
Divide the original dataset into training and testing for one time and then
train an ensemble elastic net model and do feature selection.
}
